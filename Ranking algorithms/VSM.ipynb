{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4FUKDUCHOwE"
      },
      "source": [
        "# Vector Space Model Implimentation for Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sTDhpHeGnUa"
      },
      "source": [
        "### Loading the CORPUS and fit_transform it into TIDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_excel('/content/movies_top100.xls')\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pjZdsGe1bPbf",
        "outputId": "08668e01-6543-4964-cde4-d4cf2562b252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7319acfb0138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/movies_top100.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/movies_top100.xls'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)\n",
        "corpus = data.movie_introduction.values.tolist()\n",
        "url = data.movie_url.values.tolist()\n",
        "name = data.movie_name.values.tolist()\n",
        "print(corpus)"
      ],
      "metadata": {
        "id": "IoeDxO8Ab94o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5b4eUg5V-Oh"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "#['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZVS9NYYWUUc"
      },
      "source": [
        "\n",
        "#Vector Space representation\n",
        "import pandas as pd\n",
        "vector = X\n",
        "df1 = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKx_u_-8eVet"
      },
      "source": [
        "#loading basic packages\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxYeY6HAkNBI"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSmGVRXUDtor"
      },
      "source": [
        "# Preprocessing Functions\n",
        "### Tokenizing, removing stop words and stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EDlevVigbFy"
      },
      "source": [
        "# this function returns a list of tokenized and stemmed words of any text\n",
        "def get_tokenized_list(doc_text):\n",
        "    tokens = nltk.word_tokenize(doc_text)\n",
        "    return tokens\n",
        "\n",
        "# This function will performing stemming on tokenized words\n",
        "def word_stemmer(token_list):\n",
        "  ps = nltk.stem.PorterStemmer()\n",
        "  stemmed = []\n",
        "  for words in token_list:\n",
        "    stemmed.append(ps.stem(words))\n",
        "  return stemmed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNJX_uqujMqW"
      },
      "source": [
        "# Function to remove stopwords from tokenized word list\n",
        "def remove_stopwords(doc_text):\n",
        "  cleaned_text = []\n",
        "  for words in doc_text:\n",
        "    if words not in stop_words:\n",
        "      cleaned_text.append(words)\n",
        "  return cleaned_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhvxhWsJi7u4"
      },
      "source": [
        "#Check for single document\n",
        "tokens = get_tokenized_list(corpus[1])\n",
        "print(\"WORD TOKENS:\")\n",
        "print(tokens)\n",
        "doc_text = remove_stopwords(tokens)\n",
        "print(\"\\nAFTER REMOVING STOPWORDS:\")\n",
        "print(doc_text)\n",
        "print(\"\\nAFTER PERFORMING THE WORD STEMMING::\")\n",
        "doc_text = word_stemmer(doc_text)\n",
        "doc_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q987xv-5qsls"
      },
      "source": [
        "doc_ = ' '.join(doc_text)\n",
        "doc_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phszRRvFEMFw"
      },
      "source": [
        "#Performing Preprocessing on our Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1XHcJr3vMx4"
      },
      "source": [
        "cleaned_corpus = []\n",
        "for doc in corpus:\n",
        "  tokens = get_tokenized_list(doc)\n",
        "  doc_text = remove_stopwords(tokens)\n",
        "  doc_text  = word_stemmer(doc_text)\n",
        "  doc_text = ' '.join(doc_text)\n",
        "  cleaned_corpus.append(doc_text)\n",
        "cleaned_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzmB6HR3x7vc"
      },
      "source": [
        "vectorizerX = TfidfVectorizer()\n",
        "vectorizerX.fit(cleaned_corpus)\n",
        "doc_vector = vectorizerX.transform(cleaned_corpus)\n",
        "print(vectorizerX.get_feature_names_out())\n",
        "\n",
        "print(doc_vector.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yk84d1CyrTs"
      },
      "source": [
        "df1 = pd.DataFrame(doc_vector.toarray(), columns=vectorizerX.get_feature_names_out())\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uZpxgre7DT-"
      },
      "source": [
        "#Preprocess the Query and transform it to vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYLF1iiKibSG"
      },
      "source": [
        "query = input(\"Enter your query\")\n",
        "query = get_tokenized_list(query)\n",
        "query = remove_stopwords(query)\n",
        "q = []\n",
        "for w in word_stemmer(query):\n",
        "  q.append(w)\n",
        "q = ' '.join(q)\n",
        "q\n",
        "query_vector = vectorizerX.transform([q])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjmGX-fSOUHC"
      },
      "source": [
        "#Calculate Cosine Similarty\n",
        "![alt text](https://i.stack.imgur.com/36r1U.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wm_V72GzJcD"
      },
      "source": [
        "# calculate cosine similarities\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosineSimilarities = cosine_similarity(doc_vector,query_vector).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_GYjPiQ1Dxp"
      },
      "source": [
        "related_docs_indices = cosineSimilarities.argsort()[:-10:-1]\n",
        "print(related_docs_indices)\n",
        "\n",
        "for i in related_docs_indices:\n",
        "    print(\"Movie_name : \",name[i],\"\\n Movir_URL : \",url[i],\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''"
      ],
      "metadata": {
        "id": "aS4T8UaofqHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}